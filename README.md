<!-- # Know-Your-Meal

### Goal

The goal of this project is that given a food plate (typically an Indian thali), the application should be able to detect the items in the food plate, along with their nutritional values.

### Progress so far

This is the current architecture of the core logic.

![Current Process](media/expected_process.png)

The following is a brief description of the pipeline of the project so far.

1. The end-user takes an image of their meal. They can choose to - <br>
   (a) Just contribute to the database. <br>
   (b) Know the food items in the meal. <br>
   (c) Get info about the calorific content of the food items in their meal.
2. The image is taken and passed through [grounding DINO](https://github.com/IDEA-Research/GroundingDINO) (base model, version 0.1.0) with the prompt `"food. plate. cup. bowl. cultery."`. The grounding DINO returns certain bounding boxes which are then sent to [SAM 2](https://github.com/facebookresearch/sam2) - which segments them.
3. The segmentation masks are filtered so as to separate the food masks from the non-food masks. The union of all the generated masks (food and non-food) is used to form the _cropped image_.
4. The food masks are then classified using the [PE-Core](https://huggingface.co/facebook/PE-Core-L14-336) classifer, which classifies the food masks into the different classes (currently it does using KNN with a similarity threshold of 0.6).
5. The classified masks are then processed to create various UIs, that are shown to the end user. The current UI takes the food masks in the _cropped image_, zooms them in, and uses the zoomed in frames to create a video which is shown to the end-user. The following is an example of an output video that is generated by the current pipeline.

<!-- <p align="center">
<video width="512" height="290" controls>
  <source src="media/ui6_for_readme.mp4" type="video/mp4">
</video>
</p> -->
<!--
![](media/ui6_works_perfectly-ezgif.com-video-to-gif-converter.gif)

### Future Scope

As of now, the app performs food detection based on the pipeline described above. In future we want to integrate calorie estimation of the food items as well. Further improvements could also be made on the presentation front. -->

## Project Goal

**Know-Your-Meal** aims to identify and analyze the contents of a food plate—typically an Indian thali—from an image. The system detects individual food items and provides nutritional insights, including calorie estimates.

---

## Current Progress

### System Architecture

The core logic follows this pipeline:

![Current Process](media/expected_process.png)

### Pipeline Overview

1. **User Input**  
   The user captures an image of their meal and can choose to:

   (a) Contribute the image to a growing food image database <br>
   (b) Identify the food items in the meal <br>
   (c) Get nutritional information, including estimated calorie content

2. **Object Detection**  
   The image is processed using [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO) (v0.1.0) with the prompt:  
   `"food. plate. cup. bowl. cutlery."`  
   This step generates bounding boxes around relevant items.

3. **Image Segmentation**  
   The bounding boxes are passed to [SAM 2](https://github.com/facebookresearch/sam2) for segmentation. The resulting masks are filtered to isolate **food masks** from **non-food masks**.

4. **Cropped Image Generation**  
   The union of all masks (food + non-food) is used to produce a **cropped image** that focuses on the meal.

5. **Food Classification**  
   Food masks are classified using [PE-Core](https://huggingface.co/facebook/PE-Core-L14-336), currently leveraging a KNN approach with a similarity threshold of 0.6.

6. **User Interface (UI)**  
   The system generates a dynamic UI where the food regions are zoomed in and compiled into a short video. Here's a sample output:

   ![](media/ui6_works_perfectly-ezgif.com-video-to-gif-converter.gif)

---

## Future Plans

- **Calorie Estimation:**  
  Integrate precise calorie and nutritional estimation for each identified food item.

- **Improved UI/UX:**  
  Enhance the presentation layer to provide a more intuitive and engaging user experience.
